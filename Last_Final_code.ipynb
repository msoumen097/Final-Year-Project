{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0769e4a5-839b-4703-9575-1e457db37aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter symptoms separated by commas: Joint pain, Stiffness or reduced range of motion (how far you can move a joint), Swelling (inflammation),Skin discoloration,Tenderness or sensitivity to touch around a joint, A feeling of heat or warmth near your joints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matching Symptoms...\n",
      "Top matching symptoms:\n",
      "0: lump bump neck\n",
      "1: back\n",
      "2: high body temperature\n",
      "3: muscle joint pain\n",
      "4: painful\n",
      "5: neck\n",
      "6: swelling\n",
      "7: trouble sensation\n",
      "8: painful swollen joint\n",
      "9: joint bone pain\n",
      "10: multiple painful joint\n",
      "11: decreased range motion\n",
      "12: redness\n",
      "13: stiffness\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select relevant symptoms (space-separated indices): 3 4 9 10 11 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: fever (5)\n",
      "1: headache (3)\n",
      "2: maculopapular rash (2)\n",
      "3: redness (1)\n",
      "4: swelling (1)\n",
      "5: bad breath (1)\n",
      "6: bleeding gum (1)\n",
      "7: loose teeth (1)\n",
      "8: red (1)\n",
      "9: swollen (1)\n",
      "\n",
      "Predicted Diseases:\n",
      "Arthritis: 50.32%\n",
      "Osteoarthritis: 50.32%\n",
      "Influenza: 25.16%\n",
      "Bleeding Gums: 25.16%\n",
      "Dengue: 25.16%\n",
      "Zika virus disease: 25.16%\n",
      "Rheumatic fever: 25.16%\n",
      "Yaws: 25.16%\n",
      "Impetigo: 25.16%\n",
      "Chikungunya Fever: 25.16%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import operator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "\n",
    "# Utility Functions\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def synonyms(term):\n",
    "    \"\"\"Fetch synonyms of the input term from WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(term):\n",
    "        synonyms.update(syn.lemma_names())\n",
    "    return synonyms\n",
    "\n",
    "# Load Data and Model\n",
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")  # Disease combination\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\")  # Individual Disease\n",
    "\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]\n",
    "\n",
    "with open('lr_model.pkl', 'rb') as file:\n",
    "    lr = pickle.load(file)\n",
    "\n",
    "dataset_symptoms = list(X.columns)\n",
    "\n",
    "# User Input\n",
    "def preprocess_symptoms(input_symptoms):\n",
    "    \"\"\"Preprocess user-input symptoms.\"\"\"\n",
    "    processed = []\n",
    "    for sym in input_symptoms:\n",
    "        sym = sym.strip().replace('-', ' ').replace(\"'\", '')\n",
    "        sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "        processed.append(sym)\n",
    "    return processed\n",
    "\n",
    "def expand_symptoms(symptoms):\n",
    "    \"\"\"Expand symptoms using synonyms.\"\"\"\n",
    "    expanded = []\n",
    "    for user_sym in symptoms:\n",
    "        user_sym_tokens = user_sym.split()\n",
    "        expanded_set = set()\n",
    "        for comb in range(1, len(user_sym_tokens) + 1):\n",
    "            for subset in combinations(user_sym_tokens, comb):\n",
    "                expanded_set.update(synonyms(' '.join(subset)))\n",
    "        expanded_set.add(user_sym)\n",
    "        expanded.append(' '.join(expanded_set).replace('_', ' '))\n",
    "    return expanded\n",
    "\n",
    "# Match Symptoms to Dataset\n",
    "def match_symptoms(user_symptoms):\n",
    "    \"\"\"Find matching symptoms from the dataset.\"\"\"\n",
    "    found = set()\n",
    "    for data_sym in dataset_symptoms:\n",
    "        data_sym_tokens = data_sym.split()\n",
    "        for user_sym in user_symptoms:\n",
    "            match_count = sum(1 for token in data_sym_tokens if token in user_sym.split())\n",
    "            if match_count / len(data_sym_tokens) > 0.5:\n",
    "                found.add(data_sym)\n",
    "    return list(found)\n",
    "\n",
    "# Co-occurrence-Based Symptom Suggestion\n",
    "def suggest_cooccurring_symptoms(selected_symptoms):\n",
    "    \"\"\"Suggest additional symptoms based on co-occurrence.\"\"\"\n",
    "    counter_list = []\n",
    "    dis_list = set()\n",
    "    for sym in selected_symptoms:\n",
    "        dis_list.update(set(df_norm[df_norm[sym] == 1]['label_dis']))\n",
    "\n",
    "    for dis in dis_list:\n",
    "        row = df_norm.loc[df_norm['label_dis'] == dis].values.tolist()[0][1:]\n",
    "        for idx, val in enumerate(row):\n",
    "            if val != 0 and dataset_symptoms[idx] not in selected_symptoms:\n",
    "                counter_list.append(dataset_symptoms[idx])\n",
    "\n",
    "    dict_symp = dict(Counter(counter_list))\n",
    "    return sorted(dict_symp.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Predict Disease\n",
    "def predict_disease(final_symptoms):\n",
    "    \"\"\"Predict diseases based on selected symptoms.\"\"\"\n",
    "    sample_x = [0] * len(dataset_symptoms)\n",
    "    for sym in final_symptoms:\n",
    "        sample_x[dataset_symptoms.index(sym)] = 1\n",
    "\n",
    "    prediction = lr.predict_proba([sample_x])\n",
    "    k = 10\n",
    "    diseases = sorted(set(Y['label_dis']))\n",
    "    topk = prediction[0].argsort()[-k:][::-1]\n",
    "    \n",
    "    topk_dict = {}\n",
    "    for t in topk:\n",
    "        match_sym = set()\n",
    "        row = df_norm.loc[df_norm['label_dis'] == diseases[t]].values.tolist()[0][1:]\n",
    "        for idx, val in enumerate(row):\n",
    "            if val != 0:\n",
    "                match_sym.add(dataset_symptoms[idx])\n",
    "        prob = (len(match_sym.intersection(set(final_symptoms))) + 1) / (len(set(final_symptoms)) + 1)\n",
    "        scores = cross_val_score(lr, X, Y, cv=2)\n",
    "        prob *= mean(scores)\n",
    "        topk_dict[t] = prob\n",
    "\n",
    "    return {diseases[key]: round(topk_dict[key] * 100, 2) for key in sorted(topk_dict, key=topk_dict.get, reverse=True)}\n",
    "\n",
    "# Main Workflow\n",
    "user_symptoms = input(\"Please enter symptoms separated by commas:\").lower().split(',')\n",
    "processed_user_symptoms = preprocess_symptoms(user_symptoms)\n",
    "expanded_user_symptoms = expand_symptoms(processed_user_symptoms)\n",
    "\n",
    "print(\"\\nMatching Symptoms...\")\n",
    "found_symptoms = match_symptoms(expanded_user_symptoms)\n",
    "print(\"Top matching symptoms:\")\n",
    "for idx, symp in enumerate(found_symptoms):\n",
    "    print(f\"{idx}: {symp}\")\n",
    "\n",
    "selected_indices = input(\"\\nSelect relevant symptoms (space-separated indices):\").split()\n",
    "final_symptoms = [found_symptoms[int(idx)] for idx in selected_indices]\n",
    "\n",
    "cooccurring_symptoms = suggest_cooccurring_symptoms(final_symptoms)\n",
    "for idx, (symp, count) in enumerate(cooccurring_symptoms[:10]):\n",
    "    print(f\"{idx}: {symp} ({count})\")\n",
    "\n",
    "predicted_diseases = predict_disease(final_symptoms)\n",
    "print(\"\\nPredicted Diseases:\")\n",
    "for disease, probability in predicted_diseases.items():\n",
    "    print(f\"{disease}: {probability}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a6de93-5a17-4121-a156-6e7af9451bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter symptoms separated by commas:  Dark urine,clay-colored stools, Diarrhea, Feeling tired, Fever, Joint pain,Loss of appetite,Nausea, stomach pain, vomiting,Yellow skin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing symptoms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing symptoms: 100%|███████████████████████████████████████████████████████████████| 11/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding symptoms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding symptoms: 100%|███████████████████████████████████████████████████████████████████| 11/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching symptoms from the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching symptoms: 100%|███████████████████████████████████████████████████████| 489/489 [00:00<00:00, 15102.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top matching symptoms:\n",
      "0: diarrhoea\n",
      "1: trouble sensation\n",
      "2: vomiting\n",
      "3: dark urine\n",
      "4: feeling tired\n",
      "5: red\n",
      "6: diarrhea\n",
      "7: fever\n",
      "8: stomach pain\n",
      "9: neck\n",
      "10: yellowish skin crust\n",
      "11: painful swollen joint\n",
      "12: loss appetite\n",
      "13: joint bone pain\n",
      "14: multiple painful joint\n",
      "15: blue\n",
      "16: yellow skin\n",
      "17: muscle joint pain\n",
      "18: painful\n",
      "19: yellowish skin\n",
      "20: feeling tired time\n",
      "21: nausea\n",
      "22: fatigue\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Select relevant symptoms (space-separated indices): 3 4 6 17 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggesting co-occurring symptoms...\n",
      "\n",
      "Suggested co-occurring symptoms:\n",
      "0: fever (12)\n",
      "1: testicular pain (9)\n",
      "2: vomiting (6)\n",
      "3: muscle weakness (5)\n",
      "4: shortness breath (5)\n",
      "5: nausea (4)\n",
      "6: chest pain (3)\n",
      "7: headache (3)\n",
      "8: unintended weight loss (2)\n",
      "9: maculopapular rash (2)\n",
      "Predicting diseases...\n",
      "\n",
      "Predicted Diseases:\n",
      "Influenza: 52.84%\n",
      "Hepatitis A: 52.84%\n",
      "Thalassaemia: 52.84%\n",
      "Hyperthyroidism: 35.22%\n",
      "Dengue: 35.22%\n",
      "Myocardial Infarction (Heart Attack): 35.22%\n",
      "Scurvy: 35.22%\n",
      "Lupus erythematosus: 35.22%\n",
      "Lymphoma: 35.22%\n",
      "Hepatitis B: 35.22%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import operator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# Utility Functions\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def synonyms(term):\n",
    "    \"\"\"Fetch synonyms of the input term from WordNet.\"\"\"\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(term):\n",
    "        synonyms.update(syn.lemma_names())\n",
    "    return synonyms\n",
    "\n",
    "# Load Data and Model\n",
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")  # Disease combination\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\")  # Individual Disease\n",
    "\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]\n",
    "\n",
    "with open('lr_model.pkl', 'rb') as file:\n",
    "    lr = pickle.load(file)\n",
    "\n",
    "dataset_symptoms = list(X.columns)\n",
    "\n",
    "# User Input\n",
    "def preprocess_symptoms(input_symptoms):\n",
    "    \"\"\"Preprocess user-input symptoms.\"\"\"\n",
    "    print(\"Processing symptoms...\")\n",
    "    time.sleep(1)  # Simulate processing delay\n",
    "    processed = []\n",
    "    for sym in tqdm(input_symptoms, desc=\"Preprocessing symptoms\"):\n",
    "        sym = sym.strip().replace('-', ' ').replace(\"'\", '')\n",
    "        sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "        processed.append(sym)\n",
    "    return processed\n",
    "\n",
    "def expand_symptoms(symptoms):\n",
    "    \"\"\"Expand symptoms using synonyms.\"\"\"\n",
    "    expanded = []\n",
    "    print(\"Expanding symptoms...\")\n",
    "    time.sleep(1)  # Simulate processing delay\n",
    "    for user_sym in tqdm(symptoms, desc=\"Expanding symptoms\"):\n",
    "        user_sym_tokens = user_sym.split()\n",
    "        expanded_set = set()\n",
    "        for comb in range(1, len(user_sym_tokens) + 1):\n",
    "            for subset in combinations(user_sym_tokens, comb):\n",
    "                expanded_set.update(synonyms(' '.join(subset)))\n",
    "        expanded_set.add(user_sym)\n",
    "        expanded.append(' '.join(expanded_set).replace('_', ' '))\n",
    "    return expanded\n",
    "\n",
    "# Match Symptoms to Dataset\n",
    "def match_symptoms(user_symptoms):\n",
    "    \"\"\"Find matching symptoms from the dataset.\"\"\"\n",
    "    print(\"Matching symptoms from the dataset...\")\n",
    "    time.sleep(1)\n",
    "    found = set()\n",
    "    for data_sym in tqdm(dataset_symptoms, desc=\"Matching symptoms\"):\n",
    "        data_sym_tokens = data_sym.split()\n",
    "        for user_sym in user_symptoms:\n",
    "            match_count = sum(1 for token in data_sym_tokens if token in user_sym.split())\n",
    "            if match_count / len(data_sym_tokens) > 0.5:\n",
    "                found.add(data_sym)\n",
    "    return list(found)\n",
    "\n",
    "# Co-occurrence-Based Symptom Suggestion\n",
    "def suggest_cooccurring_symptoms(selected_symptoms):\n",
    "    \"\"\"Suggest additional symptoms based on co-occurrence.\"\"\"\n",
    "    print(\"Suggesting co-occurring symptoms...\")\n",
    "    time.sleep(1)\n",
    "    counter_list = []\n",
    "    dis_list = set()\n",
    "    for sym in selected_symptoms:\n",
    "        dis_list.update(set(df_norm[df_norm[sym] == 1]['label_dis']))\n",
    "\n",
    "    for dis in dis_list:\n",
    "        row = df_norm.loc[df_norm['label_dis'] == dis].values.tolist()[0][1:]\n",
    "        for idx, val in enumerate(row):\n",
    "            if val != 0 and dataset_symptoms[idx] not in selected_symptoms:\n",
    "                counter_list.append(dataset_symptoms[idx])\n",
    "\n",
    "    dict_symp = dict(Counter(counter_list))\n",
    "    return sorted(dict_symp.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Predict Disease\n",
    "def predict_disease(final_symptoms):\n",
    "    \"\"\"Predict diseases based on selected symptoms.\"\"\"\n",
    "    print(\"Predicting diseases...\")\n",
    "    time.sleep(1)\n",
    "    sample_x = [0] * len(dataset_symptoms)\n",
    "    for sym in final_symptoms:\n",
    "        sample_x[dataset_symptoms.index(sym)] = 1\n",
    "\n",
    "    prediction = lr.predict_proba([sample_x])\n",
    "    k = 10\n",
    "    diseases = sorted(set(Y['label_dis']))\n",
    "    topk = prediction[0].argsort()[-k:][::-1]\n",
    "    \n",
    "    topk_dict = {}\n",
    "    for t in topk:\n",
    "        match_sym = set()\n",
    "        row = df_norm.loc[df_norm['label_dis'] == diseases[t]].values.tolist()[0][1:]\n",
    "        for idx, val in enumerate(row):\n",
    "            if val != 0:\n",
    "                match_sym.add(dataset_symptoms[idx])\n",
    "        prob = (len(match_sym.intersection(set(final_symptoms))) + 1) / (len(set(final_symptoms)) + 1)\n",
    "        scores = cross_val_score(lr, X, Y, cv=2)\n",
    "        prob *= mean(scores)\n",
    "        topk_dict[t] = prob\n",
    "\n",
    "    return {diseases[key]: round(topk_dict[key] * 100, 2) for key in sorted(topk_dict, key=topk_dict.get, reverse=True)}\n",
    "\n",
    "# Main Workflow\n",
    "user_symptoms = input(\"Please enter symptoms separated by commas:\").lower().split(',')\n",
    "processed_user_symptoms = preprocess_symptoms(user_symptoms)\n",
    "expanded_user_symptoms = expand_symptoms(processed_user_symptoms)\n",
    "\n",
    "found_symptoms = match_symptoms(expanded_user_symptoms)\n",
    "print(\"\\nTop matching symptoms:\")\n",
    "for idx, symp in enumerate(found_symptoms):\n",
    "    print(f\"{idx}: {symp}\")\n",
    "\n",
    "selected_indices = input(\"\\nSelect relevant symptoms (space-separated indices):\").split()\n",
    "final_symptoms = [found_symptoms[int(idx)] for idx in selected_indices]\n",
    "\n",
    "cooccurring_symptoms = suggest_cooccurring_symptoms(final_symptoms)\n",
    "print(\"\\nSuggested co-occurring symptoms:\")\n",
    "for idx, (symp, count) in enumerate(cooccurring_symptoms[:10]):\n",
    "    print(f\"{idx}: {symp} ({count})\")\n",
    "\n",
    "predicted_diseases = predict_disease(final_symptoms)\n",
    "print(\"\\nPredicted Diseases:\")\n",
    "for disease, probability in predicted_diseases.items():\n",
    "    print(f\"{disease}: {probability}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5dc7fa-6f27-4451-abad-0053c5609dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abscess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abscess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abscess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abscess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abscess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>papilloedema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8831</th>\n",
       "      <td>papilloedema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8832</th>\n",
       "      <td>papilloedema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>papilloedema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8834</th>\n",
       "      <td>papilloedema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8835 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label_dis\n",
       "0          Abscess\n",
       "1          Abscess\n",
       "2          Abscess\n",
       "3          Abscess\n",
       "4          Abscess\n",
       "...            ...\n",
       "8830  papilloedema\n",
       "8831  papilloedema\n",
       "8832  papilloedema\n",
       "8833  papilloedema\n",
       "8834  papilloedema\n",
       "\n",
       "[8835 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d745586-ef26-4093-9878-082b6ba5254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from statistics import mean\n",
    "from nltk.corpus import wordnet \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import operator\n",
    "from xgboost import XGBClassifier\n",
    "import math\n",
    "from Treatment import diseaseDetail\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472f6b24-4c20-4635-a672-665ef8dc6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter symptoms separated by comma(,):\n",
      "  Dark urine,clay-colored stools, Diarrhea, Feeling tired, Fever, Joint pain,Loss of appetite,Nausea, stomach pain, vomiting,Yellow skin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Processing all of that symtomps...........\n",
      "Processed\n",
      "Top matching symptoms from your search!\n",
      "0 : trouble sensation\n",
      "1 : diarrhoea\n",
      "2 : joint bone pain\n",
      "3 : multiple painful joint\n",
      "4 : fatigue\n",
      "5 : yellow skin\n",
      "6 : nausea\n",
      "7 : stomach pain\n",
      "8 : neck\n",
      "9 : red\n",
      "10 : yellowish skin\n",
      "11 : yellowish skin crust\n",
      "12 : blue\n",
      "13 : muscle joint pain\n",
      "14 : vomiting\n",
      "15 : loss appetite\n",
      "16 : dark urine\n",
      "17 : fever\n",
      "18 : feeling tired\n",
      "19 : diarrhea\n",
      "20 : painful\n",
      "21 : feeling tired time\n",
      "22 : painful swollen joint\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select the relevant symptoms. Enter indices (separated-space):\n",
      " 0 1 3 5 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('headache', 5), ('testicular pain', 5), ('fever', 5), ('diarrhea', 3), ('vomiting', 3), ('dizziness', 2), ('jaundice', 2), ('chest pain', 2), ('shortness breath', 2), ('confusion', 1), ('dry damp skin', 1), ('high body temperature', 1), ('red', 1), ('bloating', 1), ('gas', 1), ('blindness one eye', 1), ('double vision', 1), ('muscle weakness', 1), ('trouble coordination', 1), ('eye pain', 1), ('mid dilated pupil', 1), ('redness eye', 1), ('vision loss', 1), ('light sensitivity', 1), ('sensitivity smell', 1), ('sensitivity sound', 1), ('abdominal distention', 1), ('constipation', 1), ('dermatitis herpetiformis', 1), ('malabsorption', 1), ('none non specific', 1), ('unintended weight loss', 1), ('arm', 1), ('back', 1), ('cold sweat', 1), ('feeling faint upon standing', 1), ('feeling tired', 1), ('jaw', 1), ('neck', 1), ('stomach pain', 1), ('chill', 1), ('abscess', 1), ('small blister surrounding swelling', 1), ('muscular pain', 1), ('sore throat', 1), ('vaginal bleeding', 1), ('dark urine', 1), ('fatigue', 1), ('profuse sweating', 1), ('blood urine', 1), ('severe pain lower back abdomen', 1), ('erythema marginatum', 1), ('involuntary muscle movement', 1)]\n",
      "\n",
      "Common co-occuring symptoms:\n",
      "0 : headache\n",
      "1 : testicular pain\n",
      "2 : fever\n",
      "3 : diarrhea\n",
      "4 : vomiting\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      " 0 3 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common co-occuring symptoms:\n",
      "0 : dizziness\n",
      "1 : jaundice\n",
      "2 : chest pain\n",
      "3 : shortness breath\n",
      "4 : confusion\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\n",
      " no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final list of Symptoms that will be used for prediction:\n",
      "trouble sensation\n",
      "diarrhoea\n",
      "multiple painful joint\n",
      "yellow skin\n",
      "nausea\n",
      "headache\n",
      "diarrhea\n",
      "vomiting\n",
      "\n",
      "Top 10 diseases predicted based on symptoms\n",
      "0 Disease name: Anthrax \tProbability: 39.14%\n",
      "1 Disease name: Hepatitis A \tProbability: 39.14%\n",
      "2 Disease name: Crimean Congo haemorrhagic fever (CCHF) \tProbability: 39.14%\n",
      "3 Disease name: Ebola \tProbability: 29.35%\n",
      "4 Disease name: Yellow Fever \tProbability: 29.35%\n",
      "5 Disease name: lactose intolerance \tProbability: 29.35%\n",
      "6 Disease name: Heat-Related Illnesses and Heat waves \tProbability: 29.35%\n",
      "7 Disease name: Migraine \tProbability: 29.35%\n",
      "8 Disease name: Dehydration \tProbability: 29.35%\n",
      "9 Disease name: Calculi \tProbability: 29.35%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "More details about the disease? Enter index of disease or '-1' to discontinue and close the system:\n",
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anthrax\n",
      "Specialty -  Infectious disease \n",
      "Symptoms -    \n",
      "Skin form : small blister with surrounding swelling   \n",
      "Inhalational form : fever, chest pain, shortness of breath   \n",
      "Intestinal form : nausea, vomiting, diarrhea, abdominal pain   \n",
      "Injection form : fever, abscess     \n",
      "Usual onset -  1 day to 2 months post contact     \n",
      "Causes -   Bacillus anthracis      \n",
      "Risk factors -  Working with animals, travelers, postal workers, military personnel     \n",
      "Diagnostic method -  Based on antibodies or toxin in the blood, microbial culture     \n",
      "Prevention -  Anthrax vaccination, antibiotics     \n",
      "Treatment -  Antibiotics, antitoxin     \n",
      "Prognosis -  20–80% die without treatment     \n",
      "Frequency -  >,2,000 cases per year     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# utlities for pre-processing\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "splitter = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\") # Disease combination\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\") # Individual Disease\n",
    "\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]\n",
    "\n",
    "import pickle\n",
    "with open('lr_model.pkl', 'rb') as file:\n",
    "    lr = pickle.load(file)\n",
    "dataset_symptoms = list(X.columns)\n",
    "\n",
    "# Taking symptoms from user as input \n",
    "user_symptoms = str(input(\"Please enter symptoms separated by comma(,):\\n\")).lower().split(',')\n",
    "# Preprocessing the input symptoms\n",
    "processed_user_symptoms=[]\n",
    "for sym in user_symptoms:\n",
    "    sym=sym.strip()\n",
    "    sym=sym.replace('-',' ')\n",
    "    sym=sym.replace(\"'\",'')\n",
    "    sym = ' '.join([lemmatizer.lemmatize(word) for word in splitter.tokenize(sym)])\n",
    "    processed_user_symptoms.append(sym)\n",
    "\n",
    "# Taking each user symptom and finding all its synonyms and appending it to the pre-processed symptom string\n",
    "print(\".........Processing all of that symtomps...........\")\n",
    "for user_sym in processed_user_symptoms:\n",
    "    user_sym = user_sym.split()\n",
    "    str_sym = set()\n",
    "    for comb in range(1, len(user_sym)+1):\n",
    "        for subset in combinations(user_sym, comb):\n",
    "            subset=' '.join(subset)\n",
    "            subset = synonyms(subset) \n",
    "            str_sym.update(subset)\n",
    "    str_sym.add(' '.join(user_sym))\n",
    "    user_symptoms.append(' '.join(str_sym).replace('_',' '))\n",
    "# query expansion performed by joining synonyms found for each symptoms initially entered\n",
    "# print(\"After query expansion done by using the symptoms entered\")\n",
    "# print(user_symptoms)\n",
    "print(\"Processed\")\n",
    "found_symptoms = set()\n",
    "for idx, data_sym in enumerate(dataset_symptoms):\n",
    "    data_sym_split=data_sym.split()\n",
    "    for user_sym in user_symptoms:\n",
    "        count=0\n",
    "        for symp in data_sym_split:\n",
    "            if symp in user_sym.split():\n",
    "                count+=1\n",
    "        if count/len(data_sym_split)>0.5:\n",
    "            found_symptoms.add(data_sym)\n",
    "found_symptoms = list(found_symptoms)\n",
    "# Print all found symptoms\n",
    "print(\"Top matching symptoms from your search!\")\n",
    "for idx, symp in enumerate(found_symptoms):\n",
    "    print(idx,\":\",symp)\n",
    "    \n",
    "# Show the related symptoms found in the dataset and ask user to select among them\n",
    "select_list = input(\"\\nPlease select the relevant symptoms. Enter indices (separated-space):\\n\").split()\n",
    "\n",
    "# Find other relevant symptoms from the dataset based on user symptoms based on the highest co-occurance with the\n",
    "# ones that is input by the user\n",
    "dis_list = set()\n",
    "final_symp = [] \n",
    "counter_list = []\n",
    "for idx in select_list:\n",
    "    symp=found_symptoms[int(idx)]\n",
    "    final_symp.append(symp)\n",
    "    dis_list.update(set(df_norm[df_norm[symp]==1]['label_dis']))\n",
    "   \n",
    "for dis in dis_list:\n",
    "    row = df_norm.loc[df_norm['label_dis'] == dis].values.tolist()\n",
    "    row[0].pop(0)\n",
    "    for idx,val in enumerate(row[0]):\n",
    "        if val!=0 and dataset_symptoms[idx] not in final_symp:\n",
    "            counter_list.append(dataset_symptoms[idx])\n",
    "dict_symp = dict(Counter(counter_list))\n",
    "dict_symp_tup = sorted(dict_symp.items(), key=operator.itemgetter(1),reverse=True)   \n",
    "print(dict_symp_tup)\n",
    "# Iteratively, suggest top co-occuring symptoms to the user and ask to select the ones applicable \n",
    "found_symptoms=[]\n",
    "count=0\n",
    "for tup in dict_symp_tup:\n",
    "    count+=1\n",
    "    found_symptoms.append(tup[0])\n",
    "    if count%5==0 or count==len(dict_symp_tup):\n",
    "        print(\"\\nCommon co-occuring symptoms:\")\n",
    "        for idx,ele in enumerate(found_symptoms):\n",
    "            print(idx,\":\",ele)\n",
    "        select_list = input(\"Do you have have of these symptoms? If Yes, enter the indices (space-separated), 'no' to stop, '-1' to skip:\\n\").lower().split();\n",
    "        if select_list[0]=='no':\n",
    "            break\n",
    "        if select_list[0]=='-1':\n",
    "            found_symptoms = [] \n",
    "            continue\n",
    "        for idx in select_list:\n",
    "            final_symp.append(found_symptoms[int(idx)])\n",
    "        found_symptoms = [] \n",
    "# Create query vector based on symptoms selected by the user\n",
    "print(\"\\nFinal list of Symptoms that will be used for prediction:\")\n",
    "sample_x = [0 for x in range(0,len(dataset_symptoms))]\n",
    "for val in final_symp:\n",
    "    print(val)\n",
    "    sample_x[dataset_symptoms.index(val)]=1\n",
    "prediction = lr.predict_proba([sample_x])\n",
    "k = 10\n",
    "diseases = list(set(Y['label_dis']))\n",
    "diseases.sort()\n",
    "topk = prediction[0].argsort()[-k:][::-1]\n",
    "print(f\"\\nTop {k} diseases predicted based on symptoms\")\n",
    "topk_dict = {}\n",
    "# Show top 10 highly probable disease to the user.\n",
    "for idx,t in  enumerate(topk):\n",
    "    match_sym=set()\n",
    "    row = df_norm.loc[df_norm['label_dis'] == diseases[t]].values.tolist()\n",
    "    row[0].pop(0)\n",
    "\n",
    "    for idx,val in enumerate(row[0]):\n",
    "        if val!=0:\n",
    "            match_sym.add(dataset_symptoms[idx])\n",
    "    prob = (len(match_sym.intersection(set(final_symp)))+1)/(len(set(final_symp))+1)\n",
    "    scores = cross_val_score(lr, X, Y, cv=2)\n",
    "    prob *= mean(scores)\n",
    "    topk_dict[t] = prob\n",
    "j = 0\n",
    "topk_index_mapping = {}\n",
    "topk_sorted = dict(sorted(topk_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "for key in topk_sorted:\n",
    "  prob = topk_sorted[key]*100\n",
    "  print(str(j) + \" Disease name:\",diseases[key], \"\\tProbability:\",str(round(prob, 2))+\"%\")\n",
    "  topk_index_mapping[j] = key\n",
    "  j += 1\n",
    "\n",
    "select = input(\"\\nMore details about the disease? Enter index of disease or '-1' to discontinue and close the system:\\n\")\n",
    "if select!='-1':\n",
    "    dis=diseases[topk_index_mapping[int(select)]]\n",
    "    print()\n",
    "    print(diseaseDetail(dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2dc957f-12df-4798-b1a7-8c48c0558561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_dis                           \n",
       "Myocardial Infarction (Heart Attack)    2047\n",
       "Polycystic ovary syndrome (PCOS)         511\n",
       "Anthrax                                  511\n",
       "Porphyria                                255\n",
       "Rabies                                   255\n",
       "                                        ... \n",
       "Neoplasm                                   1\n",
       "Burns                                      1\n",
       "Fibroids                                   1\n",
       "Taeniasis/cysticercosis                    1\n",
       "Hypotonia                                  1\n",
       "Name: count, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5cde8-2f8c-4fb2-91ec-b290d7a5336e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
